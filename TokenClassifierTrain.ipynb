{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1poNlBVtKHGFZf84GyKBMBU52RXTB0c3L","authorship_tag":"ABX9TyOky6aKYL56bU9RFcgn1eH0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"ad6df545a0d14f8fb84a3eff73eead92":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5dd02a43191b491096388e9793060cc3","IPY_MODEL_07e89baaafdb482290007a3e66c3afa1","IPY_MODEL_ff258e9c94144022897f00d9f14036ad"],"layout":"IPY_MODEL_6cce604488ad4b56859ef04ef9f23df8"}},"5dd02a43191b491096388e9793060cc3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9142e3744a44e83825e1b24e382dd86","placeholder":"​","style":"IPY_MODEL_11b245e6dc1c4e71affa750dfedc8ca9","value":"Map: 100%"}},"07e89baaafdb482290007a3e66c3afa1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_db04894b291346e595112ee0259bce28","max":20,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3bea1a8c199047b59ae5c7e2ef5438ce","value":20}},"ff258e9c94144022897f00d9f14036ad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b39f9c1e88d4370979b63bc819010c5","placeholder":"​","style":"IPY_MODEL_ca5cffd5b85a49709c113b5dbf12a30f","value":" 20/20 [00:00&lt;00:00, 240.72 examples/s]"}},"6cce604488ad4b56859ef04ef9f23df8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9142e3744a44e83825e1b24e382dd86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11b245e6dc1c4e71affa750dfedc8ca9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"db04894b291346e595112ee0259bce28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bea1a8c199047b59ae5c7e2ef5438ce":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1b39f9c1e88d4370979b63bc819010c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca5cffd5b85a49709c113b5dbf12a30f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f675cb1d4768460b8068af0923252bd4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c37fe4c3a57b4bc1bd271e29d149c2e9","IPY_MODEL_c01e6249c0fa4f3f91b53f3cec5fbd6b","IPY_MODEL_06297e42e39742f99b0ec84b2f10c906"],"layout":"IPY_MODEL_0a5ea3b97fd54220a4277647d424a9cf"}},"c37fe4c3a57b4bc1bd271e29d149c2e9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_752284f893c64ddbae45d555bf5b34b7","placeholder":"​","style":"IPY_MODEL_087405466f44409e81607a88bd34f203","value":"Map: 100%"}},"c01e6249c0fa4f3f91b53f3cec5fbd6b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad279554a1c04c61863f70991a644660","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ea67e2cbddb44d6e915ea2878c665dd0","value":4}},"06297e42e39742f99b0ec84b2f10c906":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_def368fa69eb46f5a84f31f76f1a5d18","placeholder":"​","style":"IPY_MODEL_fa4f4484d47040db808b3b25644c69d5","value":" 4/4 [00:00&lt;00:00, 70.88 examples/s]"}},"0a5ea3b97fd54220a4277647d424a9cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"752284f893c64ddbae45d555bf5b34b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"087405466f44409e81607a88bd34f203":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad279554a1c04c61863f70991a644660":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea67e2cbddb44d6e915ea2878c665dd0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"def368fa69eb46f5a84f31f76f1a5d18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa4f4484d47040db808b3b25644c69d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install dataset\n","!pip install evaluate\n","!pip install seqeval\n","!pip install transformers --upgrade"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KFkf--X6dQ1H","executionInfo":{"status":"ok","timestamp":1716044628617,"user_tz":-180,"elapsed":72312,"user":{"displayName":"Никита Масловский","userId":"15665865335602303397"}},"outputId":"19f04fb2-41ca-4396-ffa0-fedc4d12c387","collapsed":true},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting dataset\n","  Downloading dataset-1.6.2-py2.py3-none-any.whl (18 kB)\n","Collecting sqlalchemy<2.0.0,>=1.3.2 (from dataset)\n","  Downloading SQLAlchemy-1.4.52-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting alembic>=0.6.2 (from dataset)\n","  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting banal>=1.0.1 (from dataset)\n","  Downloading banal-1.0.6-py2.py3-none-any.whl (6.1 kB)\n","Collecting Mako (from alembic>=0.6.2->dataset)\n","  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=0.6.2->dataset) (4.11.0)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<2.0.0,>=1.3.2->dataset) (3.0.3)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=0.6.2->dataset) (2.1.5)\n","Installing collected packages: banal, sqlalchemy, Mako, alembic, dataset\n","  Attempting uninstall: sqlalchemy\n","    Found existing installation: SQLAlchemy 2.0.30\n","    Uninstalling SQLAlchemy-2.0.30:\n","      Successfully uninstalled SQLAlchemy-2.0.30\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.4.52 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed Mako-1.3.5 alembic-1.13.1 banal-1.0.6 dataset-1.6.2 sqlalchemy-1.4.52\n","Collecting evaluate\n","  Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting datasets>=2.0.0 (from evaluate)\n","  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.25.2)\n","Collecting dill (from evaluate)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.0.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.4)\n","Collecting xxhash (from evaluate)\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from evaluate)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.20.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.14.0)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.5)\n","Collecting huggingface-hub>=0.7.0 (from evaluate)\n","  Downloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n","Installing collected packages: xxhash, dill, multiprocess, huggingface-hub, datasets, evaluate\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.20.3\n","    Uninstalling huggingface-hub-0.20.3:\n","      Successfully uninstalled huggingface-hub-0.20.3\n","Successfully installed datasets-2.19.1 dill-0.3.8 evaluate-0.4.2 huggingface-hub-0.23.0 multiprocess-0.70.16 xxhash-3.4.1\n","Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.25.2)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=fe6e79a47e487d6bc0de2c4964cc931fa153c3f59f32e598a0265b0b311524be\n","  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.2)\n","Collecting transformers\n","  Downloading transformers-4.41.0-py3-none-any.whl (9.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n","Installing collected packages: transformers\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.40.2\n","    Uninstalling transformers-4.40.2:\n","      Successfully uninstalled transformers-4.40.2\n","Successfully installed transformers-4.41.0\n"]}]},{"cell_type":"code","source":["!pip install transformers[torch]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d9wyLsqA17Dk","executionInfo":{"status":"ok","timestamp":1716044718476,"user_tz":-180,"elapsed":89890,"user":{"displayName":"Никита Масловский","userId":"15665865335602303397"}},"outputId":"5433c6a2-4858-4303-e4a8-f30b27e7e7bf","collapsed":true},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.41.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.14.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.2.1+cu121)\n","Collecting accelerate>=0.21.0 (from transformers[torch])\n","  Downloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->transformers[torch])\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->transformers[torch])\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->transformers[torch])\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->transformers[torch])\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->transformers[torch])\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->transformers[torch])\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->transformers[torch])\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->transformers[torch])\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->transformers[torch])\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch->transformers[torch])\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->transformers[torch])\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch])\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n","Successfully installed accelerate-0.30.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"]}]},{"cell_type":"code","execution_count":32,"metadata":{"id":"gGOGvP0cp28Z","executionInfo":{"status":"ok","timestamp":1716047769518,"user_tz":-180,"elapsed":602,"user":{"displayName":"Никита Масловский","userId":"15665865335602303397"}}},"outputs":[],"source":["import numpy as np\n","\n","from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer, DataCollatorForTokenClassification\n","from datasets import Dataset\n","import evaluate"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"shUFdK2bw9OZ","executionInfo":{"status":"ok","timestamp":1716044776776,"user_tz":-180,"elapsed":40300,"user":{"displayName":"Никита Масловский","userId":"15665865335602303397"}},"outputId":"9ebc1380-ed44-4239-ba40-0924465cf2a0"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["def read_and_process_data(file_path, labels):\n","    # Чтение файла и разделение его на строки\n","    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n","        lines = f.readlines()\n","\n","    id2label = {idx: label for idx, label in enumerate(labels)}\n","    label2id = {label: idx for idx, label in id2label.items()}\n","\n","    # Создание списка для хранения текста и меток\n","    texts = []\n","    labels = []\n","\n","    # Проход по строкам файла и разделение на текст и метки\n","    text = []\n","    label = []\n","    for line in lines:\n","        line = line.strip().split()\n","        if line:\n","            word, word_label = line\n","            text.append(word)\n","            label.append(label2id[word_label])\n","        elif text and label:\n","            texts.append(text)\n","            labels.append(label)\n","            text = []\n","            label = []\n","    if text and label:\n","            texts.append(text)\n","            labels.append(label)\n","            # Пустая строка разделяет примеры\n","    # Создание набора данных\n","    dataset = Dataset.from_dict({\"tokens\": texts, \"ner_tags\": labels})\n","    return dataset, label2id, id2label"],"metadata":{"id":"3QY3Fv-MDm-3","executionInfo":{"status":"ok","timestamp":1716047852573,"user_tz":-180,"elapsed":942,"user":{"displayName":"Никита Масловский","userId":"15665865335602303397"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["label_list = [\"O\", \"B-VIOLATION\", \"I-VIOLATION\", \"B-MISSING-BEFORE\", \"B-MISSING-AFTER\"]\n","dataset, label2id, id2label = read_and_process_data(\"/content/drive/MyDrive/Хакатон УрФ 2024/Data.txt\", label_list)"],"metadata":{"id":"DOE2tRTOEYkY","executionInfo":{"status":"ok","timestamp":1716049794628,"user_tz":-180,"elapsed":451,"user":{"displayName":"Никита Масловский","userId":"15665865335602303397"}}},"execution_count":99,"outputs":[]},{"cell_type":"code","source":["dataset = dataset.train_test_split(test_size=1/6)"],"metadata":{"id":"IfRY_e0vzA_m","executionInfo":{"status":"ok","timestamp":1716049795180,"user_tz":-180,"elapsed":4,"user":{"displayName":"Никита Масловский","userId":"15665865335602303397"}}},"execution_count":100,"outputs":[]},{"cell_type":"code","source":["dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BpncS2pX9Va0","executionInfo":{"status":"ok","timestamp":1716049805792,"user_tz":-180,"elapsed":784,"user":{"displayName":"Никита Масловский","userId":"15665865335602303397"}},"outputId":"0a7bb827-0a91-4e12-f69b-d9d45fa267c7"},"execution_count":101,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['tokens', 'ner_tags'],\n","        num_rows: 20\n","    })\n","    test: Dataset({\n","        features: ['tokens', 'ner_tags'],\n","        num_rows: 4\n","    })\n","})"]},"metadata":{},"execution_count":101}]},{"cell_type":"code","source":["model_path = \"KoichiYasuoka/bert-base-russian-upos\"\n","tokenizer = AutoTokenizer.from_pretrained(model_path)\n","model = AutoModelForTokenClassification.from_pretrained(model_path, num_labels=len(label_list), ignore_mismatched_sizes=True, id2label=id2label, label2id=label2id)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EjBInoM5ajvS","executionInfo":{"status":"ok","timestamp":1716050602369,"user_tz":-180,"elapsed":2787,"user":{"displayName":"Никита Масловский","userId":"15665865335602303397"}},"outputId":"8f0629a0-ce85-4a99-9f16-87bab66e7bb3"},"execution_count":128,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForTokenClassification were not initialized from the model checkpoint at KoichiYasuoka/bert-base-russian-upos and are newly initialized because the shapes did not match:\n","- classifier.weight: found shape torch.Size([89, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n","- classifier.bias: found shape torch.Size([89]) in the checkpoint and torch.Size([5]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["def tokenize_and_align_labels(examples):\n","    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n","\n","    labels = []\n","    for i, label in enumerate(examples[f\"ner_tags\"]):\n","        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n","        previous_word_idx = None\n","        label_ids = []\n","        for word_idx in word_ids:  # Set the special tokens to -100.\n","            if word_idx is None:\n","                label_ids.append(-100)\n","            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n","                label_ids.append(label[word_idx])\n","            else:\n","                label_ids.append(-100)\n","            previous_word_idx = word_idx\n","        labels.append(label_ids)\n","\n","    tokenized_inputs[\"labels\"] = labels\n","    return tokenized_inputs"],"metadata":{"id":"QV3z_8gIEoKP","executionInfo":{"status":"ok","timestamp":1716050606904,"user_tz":-180,"elapsed":788,"user":{"displayName":"Никита Масловский","userId":"15665865335602303397"}}},"execution_count":129,"outputs":[]},{"cell_type":"code","source":["tokenized_dataset = dataset.map(tokenize_and_align_labels, batched=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":117,"referenced_widgets":["ad6df545a0d14f8fb84a3eff73eead92","5dd02a43191b491096388e9793060cc3","07e89baaafdb482290007a3e66c3afa1","ff258e9c94144022897f00d9f14036ad","6cce604488ad4b56859ef04ef9f23df8","f9142e3744a44e83825e1b24e382dd86","11b245e6dc1c4e71affa750dfedc8ca9","db04894b291346e595112ee0259bce28","3bea1a8c199047b59ae5c7e2ef5438ce","1b39f9c1e88d4370979b63bc819010c5","ca5cffd5b85a49709c113b5dbf12a30f","f675cb1d4768460b8068af0923252bd4","c37fe4c3a57b4bc1bd271e29d149c2e9","c01e6249c0fa4f3f91b53f3cec5fbd6b","06297e42e39742f99b0ec84b2f10c906","0a5ea3b97fd54220a4277647d424a9cf","752284f893c64ddbae45d555bf5b34b7","087405466f44409e81607a88bd34f203","ad279554a1c04c61863f70991a644660","ea67e2cbddb44d6e915ea2878c665dd0","def368fa69eb46f5a84f31f76f1a5d18","fa4f4484d47040db808b3b25644c69d5"]},"id":"200hanNMFVPo","executionInfo":{"status":"ok","timestamp":1716050608631,"user_tz":-180,"elapsed":21,"user":{"displayName":"Никита Масловский","userId":"15665865335602303397"}},"outputId":"1f15872c-91ea-47db-c74c-cae4b1429338"},"execution_count":130,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/20 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad6df545a0d14f8fb84a3eff73eead92"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/4 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f675cb1d4768460b8068af0923252bd4"}},"metadata":{}}]},{"cell_type":"code","source":["data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"],"metadata":{"id":"rW-I8Wf1dGvN","executionInfo":{"status":"ok","timestamp":1716050609984,"user_tz":-180,"elapsed":7,"user":{"displayName":"Никита Масловский","userId":"15665865335602303397"}}},"execution_count":131,"outputs":[]},{"cell_type":"code","source":["seqeval = evaluate.load(\"seqeval\")"],"metadata":{"id":"rrHpd1QGeGWV","executionInfo":{"status":"ok","timestamp":1716050613726,"user_tz":-180,"elapsed":786,"user":{"displayName":"Никита Масловский","userId":"15665865335602303397"}}},"execution_count":132,"outputs":[]},{"cell_type":"code","source":["def compute_metrics(p):\n","    predictions, labels = p\n","    predictions = np.argmax(predictions, axis=2)\n","\n","    true_predictions = [\n","        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    true_labels = [\n","        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","\n","    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n","    return {\n","        \"precision\": results[\"overall_precision\"],\n","        \"recall\": results[\"overall_recall\"],\n","        \"f1\": results[\"overall_f1\"],\n","        \"accuracy\": results[\"overall_accuracy\"],\n","    }"],"metadata":{"id":"ZGEMzJZpdJiB","executionInfo":{"status":"ok","timestamp":1716050613726,"user_tz":-180,"elapsed":4,"user":{"displayName":"Никита Масловский","userId":"15665865335602303397"}}},"execution_count":133,"outputs":[]},{"cell_type":"code","source":["training_args = TrainingArguments(\n","    output_dir=\"TokenClassifierResults\",\n","    learning_rate=1e-5,\n","    per_device_train_batch_size=4,\n","    per_device_eval_batch_size=4,\n","    num_train_epochs=200,\n","    weight_decay=0.01,\n","    save_strategy=\"steps\",\n","    evaluation_strategy = 'steps',\n","    logging_strategy = 'steps',\n","    eval_steps = 10, # Evaluation and Save happens every 10 steps\n","    save_total_limit = 5, # Only last 5 models are saved. Older ones are deleted.\n","    load_best_model_at_end=True\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_dataset[\"train\"],\n","    eval_dataset=tokenized_dataset[\"test\"],\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics\n",")\n","\n","trainer.train()\n","\n","model.save_pretrained(\"/content/drive/MyDrive/Хакатон УрФ 2024/TokenClassifierModel\")\n","tokenizer.save_pretrained(\"/content/drive/MyDrive/Хакатон УрФ 2024/TokenClassifierModel\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"8NFNtZyOrWit","executionInfo":{"status":"ok","timestamp":1716051557854,"user_tz":-180,"elapsed":256604,"user":{"displayName":"Никита Масловский","userId":"15665865335602303397"}},"outputId":"65df7571-93dd-43f9-9489-421553d29c2c"},"execution_count":153,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1000/1000 04:05, Epoch 200/200]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>No log</td>\n","      <td>1.161892</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.861210</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>No log</td>\n","      <td>1.027630</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.857651</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>No log</td>\n","      <td>1.113064</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.861210</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>No log</td>\n","      <td>1.156984</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.861210</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>No log</td>\n","      <td>1.145696</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.864769</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>No log</td>\n","      <td>1.172357</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.864769</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>No log</td>\n","      <td>1.183761</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.868327</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>No log</td>\n","      <td>1.193548</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.868327</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>No log</td>\n","      <td>1.138003</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.864769</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>No log</td>\n","      <td>1.199569</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.864769</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>No log</td>\n","      <td>1.188741</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.864769</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>No log</td>\n","      <td>1.101985</td>\n","      <td>0.142857</td>\n","      <td>0.083333</td>\n","      <td>0.105263</td>\n","      <td>0.868327</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>No log</td>\n","      <td>1.182513</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.864769</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>No log</td>\n","      <td>1.203204</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.864769</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>No log</td>\n","      <td>1.182605</td>\n","      <td>0.166667</td>\n","      <td>0.083333</td>\n","      <td>0.111111</td>\n","      <td>0.864769</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>No log</td>\n","      <td>1.190782</td>\n","      <td>0.200000</td>\n","      <td>0.083333</td>\n","      <td>0.117647</td>\n","      <td>0.868327</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>No log</td>\n","      <td>1.203515</td>\n","      <td>0.200000</td>\n","      <td>0.083333</td>\n","      <td>0.117647</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>No log</td>\n","      <td>1.197272</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.868327</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>No log</td>\n","      <td>1.205468</td>\n","      <td>0.200000</td>\n","      <td>0.083333</td>\n","      <td>0.117647</td>\n","      <td>0.868327</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>No log</td>\n","      <td>1.219712</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>No log</td>\n","      <td>1.223596</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>No log</td>\n","      <td>1.235787</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>No log</td>\n","      <td>1.254937</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>No log</td>\n","      <td>1.268405</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.868327</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>No log</td>\n","      <td>1.245127</td>\n","      <td>0.166667</td>\n","      <td>0.083333</td>\n","      <td>0.111111</td>\n","      <td>0.868327</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>No log</td>\n","      <td>1.260669</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.864769</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>No log</td>\n","      <td>1.322758</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.864769</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>No log</td>\n","      <td>1.234164</td>\n","      <td>0.166667</td>\n","      <td>0.083333</td>\n","      <td>0.111111</td>\n","      <td>0.864769</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>No log</td>\n","      <td>1.301587</td>\n","      <td>0.500000</td>\n","      <td>0.083333</td>\n","      <td>0.142857</td>\n","      <td>0.868327</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>No log</td>\n","      <td>1.325722</td>\n","      <td>0.500000</td>\n","      <td>0.083333</td>\n","      <td>0.142857</td>\n","      <td>0.868327</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>No log</td>\n","      <td>1.180040</td>\n","      <td>0.142857</td>\n","      <td>0.083333</td>\n","      <td>0.105263</td>\n","      <td>0.864769</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>No log</td>\n","      <td>1.214314</td>\n","      <td>0.250000</td>\n","      <td>0.083333</td>\n","      <td>0.125000</td>\n","      <td>0.868327</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>No log</td>\n","      <td>1.239506</td>\n","      <td>0.333333</td>\n","      <td>0.083333</td>\n","      <td>0.133333</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>No log</td>\n","      <td>1.233652</td>\n","      <td>0.333333</td>\n","      <td>0.083333</td>\n","      <td>0.133333</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>No log</td>\n","      <td>1.228508</td>\n","      <td>0.250000</td>\n","      <td>0.083333</td>\n","      <td>0.125000</td>\n","      <td>0.875445</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>No log</td>\n","      <td>1.240813</td>\n","      <td>0.333333</td>\n","      <td>0.083333</td>\n","      <td>0.133333</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>No log</td>\n","      <td>1.278727</td>\n","      <td>0.333333</td>\n","      <td>0.083333</td>\n","      <td>0.133333</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>No log</td>\n","      <td>1.279131</td>\n","      <td>0.333333</td>\n","      <td>0.083333</td>\n","      <td>0.133333</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>No log</td>\n","      <td>1.274110</td>\n","      <td>0.250000</td>\n","      <td>0.083333</td>\n","      <td>0.125000</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>No log</td>\n","      <td>1.201127</td>\n","      <td>0.200000</td>\n","      <td>0.083333</td>\n","      <td>0.117647</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>No log</td>\n","      <td>1.188049</td>\n","      <td>0.166667</td>\n","      <td>0.083333</td>\n","      <td>0.111111</td>\n","      <td>0.868327</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>No log</td>\n","      <td>1.219307</td>\n","      <td>0.250000</td>\n","      <td>0.083333</td>\n","      <td>0.125000</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>No log</td>\n","      <td>1.253030</td>\n","      <td>0.250000</td>\n","      <td>0.083333</td>\n","      <td>0.125000</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>No log</td>\n","      <td>1.286196</td>\n","      <td>0.250000</td>\n","      <td>0.083333</td>\n","      <td>0.125000</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>No log</td>\n","      <td>1.309566</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.868327</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>No log</td>\n","      <td>1.314853</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.868327</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>No log</td>\n","      <td>1.313168</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.868327</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>No log</td>\n","      <td>1.243657</td>\n","      <td>0.250000</td>\n","      <td>0.083333</td>\n","      <td>0.125000</td>\n","      <td>0.868327</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>No log</td>\n","      <td>1.230571</td>\n","      <td>0.250000</td>\n","      <td>0.083333</td>\n","      <td>0.125000</td>\n","      <td>0.868327</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.004100</td>\n","      <td>1.255113</td>\n","      <td>0.250000</td>\n","      <td>0.083333</td>\n","      <td>0.125000</td>\n","      <td>0.868327</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.004100</td>\n","      <td>1.278740</td>\n","      <td>0.250000</td>\n","      <td>0.083333</td>\n","      <td>0.125000</td>\n","      <td>0.868327</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.004100</td>\n","      <td>1.293383</td>\n","      <td>0.250000</td>\n","      <td>0.083333</td>\n","      <td>0.125000</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.004100</td>\n","      <td>1.300897</td>\n","      <td>0.250000</td>\n","      <td>0.083333</td>\n","      <td>0.125000</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.004100</td>\n","      <td>1.305755</td>\n","      <td>0.250000</td>\n","      <td>0.083333</td>\n","      <td>0.125000</td>\n","      <td>0.875445</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.004100</td>\n","      <td>1.314218</td>\n","      <td>0.333333</td>\n","      <td>0.083333</td>\n","      <td>0.133333</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.004100</td>\n","      <td>1.319676</td>\n","      <td>0.333333</td>\n","      <td>0.083333</td>\n","      <td>0.133333</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.004100</td>\n","      <td>1.320902</td>\n","      <td>0.333333</td>\n","      <td>0.083333</td>\n","      <td>0.133333</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.004100</td>\n","      <td>1.295822</td>\n","      <td>0.250000</td>\n","      <td>0.083333</td>\n","      <td>0.125000</td>\n","      <td>0.868327</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.004100</td>\n","      <td>1.311014</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.864769</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.004100</td>\n","      <td>1.320219</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.864769</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.004100</td>\n","      <td>1.322723</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.864769</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.004100</td>\n","      <td>1.320175</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.864769</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.004100</td>\n","      <td>1.313106</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.868327</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.004100</td>\n","      <td>1.306327</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.868327</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.004100</td>\n","      <td>1.291654</td>\n","      <td>0.250000</td>\n","      <td>0.083333</td>\n","      <td>0.125000</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.004100</td>\n","      <td>1.294539</td>\n","      <td>0.250000</td>\n","      <td>0.083333</td>\n","      <td>0.125000</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.004100</td>\n","      <td>1.321844</td>\n","      <td>0.333333</td>\n","      <td>0.083333</td>\n","      <td>0.133333</td>\n","      <td>0.868327</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.004100</td>\n","      <td>1.334734</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.868327</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.004100</td>\n","      <td>1.337015</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.868327</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.004100</td>\n","      <td>1.311337</td>\n","      <td>0.250000</td>\n","      <td>0.083333</td>\n","      <td>0.125000</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.004100</td>\n","      <td>1.281781</td>\n","      <td>0.250000</td>\n","      <td>0.083333</td>\n","      <td>0.125000</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.004100</td>\n","      <td>1.290716</td>\n","      <td>0.250000</td>\n","      <td>0.083333</td>\n","      <td>0.125000</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.004100</td>\n","      <td>1.275887</td>\n","      <td>0.250000</td>\n","      <td>0.083333</td>\n","      <td>0.125000</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.004100</td>\n","      <td>1.271497</td>\n","      <td>0.250000</td>\n","      <td>0.083333</td>\n","      <td>0.125000</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.004100</td>\n","      <td>1.278948</td>\n","      <td>0.250000</td>\n","      <td>0.083333</td>\n","      <td>0.125000</td>\n","      <td>0.875445</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.004100</td>\n","      <td>1.248337</td>\n","      <td>0.200000</td>\n","      <td>0.083333</td>\n","      <td>0.117647</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.004100</td>\n","      <td>1.211911</td>\n","      <td>0.142857</td>\n","      <td>0.083333</td>\n","      <td>0.105263</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.004100</td>\n","      <td>1.211003</td>\n","      <td>0.142857</td>\n","      <td>0.083333</td>\n","      <td>0.105263</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.004100</td>\n","      <td>1.268788</td>\n","      <td>0.200000</td>\n","      <td>0.083333</td>\n","      <td>0.117647</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.004100</td>\n","      <td>1.287139</td>\n","      <td>0.200000</td>\n","      <td>0.083333</td>\n","      <td>0.117647</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.004100</td>\n","      <td>1.294495</td>\n","      <td>0.250000</td>\n","      <td>0.083333</td>\n","      <td>0.125000</td>\n","      <td>0.875445</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.004100</td>\n","      <td>1.299223</td>\n","      <td>0.250000</td>\n","      <td>0.083333</td>\n","      <td>0.125000</td>\n","      <td>0.875445</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.004100</td>\n","      <td>1.302525</td>\n","      <td>0.250000</td>\n","      <td>0.083333</td>\n","      <td>0.125000</td>\n","      <td>0.875445</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.004100</td>\n","      <td>1.303789</td>\n","      <td>0.250000</td>\n","      <td>0.083333</td>\n","      <td>0.125000</td>\n","      <td>0.875445</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.004100</td>\n","      <td>1.306796</td>\n","      <td>0.250000</td>\n","      <td>0.083333</td>\n","      <td>0.125000</td>\n","      <td>0.875445</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.004100</td>\n","      <td>1.306411</td>\n","      <td>0.250000</td>\n","      <td>0.083333</td>\n","      <td>0.125000</td>\n","      <td>0.875445</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.004100</td>\n","      <td>1.306532</td>\n","      <td>0.250000</td>\n","      <td>0.083333</td>\n","      <td>0.125000</td>\n","      <td>0.875445</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.004100</td>\n","      <td>1.307357</td>\n","      <td>0.250000</td>\n","      <td>0.083333</td>\n","      <td>0.125000</td>\n","      <td>0.875445</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.004100</td>\n","      <td>1.308331</td>\n","      <td>0.250000</td>\n","      <td>0.083333</td>\n","      <td>0.125000</td>\n","      <td>0.875445</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.004100</td>\n","      <td>1.307565</td>\n","      <td>0.250000</td>\n","      <td>0.083333</td>\n","      <td>0.125000</td>\n","      <td>0.875445</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.004100</td>\n","      <td>1.309447</td>\n","      <td>0.250000</td>\n","      <td>0.083333</td>\n","      <td>0.125000</td>\n","      <td>0.875445</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.004100</td>\n","      <td>1.297458</td>\n","      <td>0.200000</td>\n","      <td>0.083333</td>\n","      <td>0.117647</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.004100</td>\n","      <td>1.284646</td>\n","      <td>0.200000</td>\n","      <td>0.083333</td>\n","      <td>0.117647</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.004100</td>\n","      <td>1.281477</td>\n","      <td>0.200000</td>\n","      <td>0.083333</td>\n","      <td>0.117647</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.004100</td>\n","      <td>1.281288</td>\n","      <td>0.200000</td>\n","      <td>0.083333</td>\n","      <td>0.117647</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.004100</td>\n","      <td>1.281679</td>\n","      <td>0.200000</td>\n","      <td>0.083333</td>\n","      <td>0.117647</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.004100</td>\n","      <td>1.282548</td>\n","      <td>0.200000</td>\n","      <td>0.083333</td>\n","      <td>0.117647</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.004100</td>\n","      <td>1.282961</td>\n","      <td>0.200000</td>\n","      <td>0.083333</td>\n","      <td>0.117647</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.004100</td>\n","      <td>1.283112</td>\n","      <td>0.200000</td>\n","      <td>0.083333</td>\n","      <td>0.117647</td>\n","      <td>0.871886</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.000500</td>\n","      <td>1.284147</td>\n","      <td>0.200000</td>\n","      <td>0.083333</td>\n","      <td>0.117647</td>\n","      <td>0.871886</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"execute_result","data":{"text/plain":["('/content/drive/MyDrive/Хакатон УрФ 2024/TokenClassifierModel/tokenizer_config.json',\n"," '/content/drive/MyDrive/Хакатон УрФ 2024/TokenClassifierModel/special_tokens_map.json',\n"," '/content/drive/MyDrive/Хакатон УрФ 2024/TokenClassifierModel/vocab.txt',\n"," '/content/drive/MyDrive/Хакатон УрФ 2024/TokenClassifierModel/added_tokens.json',\n"," '/content/drive/MyDrive/Хакатон УрФ 2024/TokenClassifierModel/tokenizer.json')"]},"metadata":{},"execution_count":153}]},{"cell_type":"code","source":["inputs = tokenizer(\n","            dataset[\"train\"][2][\"tokens\"],\n","            truncation=True,\n","            is_split_into_words=True,\n","            return_tensors='pt',\n","        )\n","inputs.to(\"cuda\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OqQLve8yh4FC","executionInfo":{"status":"ok","timestamp":1716049925017,"user_tz":-180,"elapsed":587,"user":{"displayName":"Никита Масловский","userId":"15665865335602303397"}},"outputId":"978ed8fa-6323-475a-deb7-333e8624ea1b"},"execution_count":108,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([[   101,  18371,    145,  75275,  27070,   4007,    130,  54333, 109258,\n","           2325,  18371,    145,  27070,   4007,    130,  54333, 109258,   2325,\n","           9257,  62475,  77489,    845,   7769, 109258,   2325, 105282,   8953,\n","            128,    625,    130,    625,    128,  12588,  86501,    128,    625,\n","            130,    625,   7382,   1916,  12588,   7309,   3049,   5806,   3955,\n","           9688,   1580,  54333, 109258,   1636,   5022,  29526,   9798,  16636,\n","            128,  85616,    896,   1699,  17530,    842,  38322,  15529,  10766,\n","         111267,    822,  45113,    132,  38322,  15529,  45113,    132,  71576,\n","            102]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1]], device='cuda:0')}"]},"metadata":{},"execution_count":108}]},{"cell_type":"code","source":["from transformers import pipeline\n","classifier = pipeline(\"ner\", model=\"/content/drive/MyDrive/Хакатон УрФ 2024/TokenClassifierModel\", tokenizer=\"/content/drive/MyDrive/Хакатон УрФ 2024/TokenClassifierModel\")"],"metadata":{"id":"WZSOifNXd2sa","executionInfo":{"status":"ok","timestamp":1716052119614,"user_tz":-180,"elapsed":3465,"user":{"displayName":"Никита Масловский","userId":"15665865335602303397"}}},"execution_count":172,"outputs":[]},{"cell_type":"code","source":["classifier(\"Здравствуйте, на приближении станции Уралтау. 4 маршрут, проходной Уралтау, слушаю.Здравствуйте, по станции Уралтау, входной вам открыт, на 4-й путь, выходной, судоход запрещающий, на 1-й путь нечетный прибудет, проходы будут, буду пропускать по 4-му ДНЦ Мухамедьярова.Здравствуйте, понятно, Уралтау, маршрут на 4-й, боковой, свободный путь, выходной, судоход запрещающий, по прибытию нечетного будете дальше спрятать, ДНЦ Мухамедьярова.Верно.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hprw4GBPrSGV","executionInfo":{"status":"ok","timestamp":1716052336417,"user_tz":-180,"elapsed":998,"user":{"displayName":"Никита Масловский","userId":"15665865335602303397"}},"outputId":"2d7370c3-e06a-4b30-ecd2-8a791ee4ecc6"},"execution_count":183,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'entity': 'B-VIOLATION',\n","  'score': 0.99206334,\n","  'index': 20,\n","  'word': 'Здравствуй',\n","  'start': 83,\n","  'end': 93},\n"," {'entity': 'B-VIOLATION',\n","  'score': 0.60090625,\n","  'index': 68,\n","  'word': 'Здравствуй',\n","  'start': 269,\n","  'end': 279},\n"," {'entity': 'B-VIOLATION',\n","  'score': 0.6967991,\n","  'index': 97,\n","  'word': 'дальше',\n","  'start': 402,\n","  'end': 408}]"]},"metadata":{},"execution_count":183}]},{"cell_type":"code","source":["import torch\n","\n","n = 1\n","inputs = tokenizer(dataset[\"test\"][n][\"tokens\"], truncation=True, is_split_into_words=True, return_tensors=\"pt\")\n","with torch.no_grad():\n","    logits = model(**inputs.to(\"cuda\")).logits\n","\n","predictions = torch.argmax(logits, dim=2)\n","predicted_token_class = list(zip((i.item() for i in predictions[0]), dataset[\"test\"][n][\"ner_tags\"]))\n","predicted_token_class"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z4A9mHQ-jAMg","executionInfo":{"status":"ok","timestamp":1716052031287,"user_tz":-180,"elapsed":542,"user":{"displayName":"Никита Масловский","userId":"15665865335602303397"}},"outputId":"29dea5b5-fec5-4fe7-a9f2-674be2c96f8a"},"execution_count":171,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 0),\n"," (0, 0),\n"," (0, 0),\n"," (0, 0),\n"," (0, 0),\n"," (0, 0),\n"," (0, 0),\n"," (0, 0),\n"," (0, 0),\n"," (0, 0),\n"," (0, 0),\n"," (0, 0),\n"," (0, 0),\n"," (0, 0),\n"," (0, 0),\n"," (0, 0),\n"," (0, 1),\n"," (0, 2),\n"," (0, 0),\n"," (0, 0),\n"," (0, 0),\n"," (0, 0),\n"," (0, 1),\n"," (0, 0),\n"," (0, 0),\n"," (0, 0),\n"," (0, 0),\n"," (2, 0),\n"," (0, 0),\n"," (0, 0),\n"," (0, 1),\n"," (0, 2),\n"," (0, 2),\n"," (0, 2),\n"," (0, 2),\n"," (0, 2),\n"," (0, 2),\n"," (0, 2),\n"," (0, 2),\n"," (0, 2),\n"," (0, 2),\n"," (0, 2),\n"," (0, 2),\n"," (0, 2),\n"," (0, 2),\n"," (0, 0),\n"," (0, 0),\n"," (0, 0),\n"," (0, 1),\n"," (0, 2),\n"," (0, 0),\n"," (0, 0),\n"," (0, 0),\n"," (0, 0),\n"," (0, 0),\n"," (0, 0),\n"," (0, 0),\n"," (0, 0),\n"," (0, 0),\n"," (0, 0),\n"," (0, 0),\n"," (0, 1),\n"," (0, 2),\n"," (0, 0),\n"," (0, 0),\n"," (0, 1),\n"," (0, 2),\n"," (0, 2),\n"," (0, 2),\n"," (0, 2),\n"," (0, 2),\n"," (0, 0),\n"," (0, 0),\n"," (0, 0),\n"," (0, 0),\n"," (0, 1),\n"," (0, 2),\n"," (0, 2)]"]},"metadata":{},"execution_count":171}]},{"cell_type":"code","source":["dataset[\"train\"][1][\"ner_tags\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qk2KdlIKjc0v","executionInfo":{"status":"ok","timestamp":1716050965840,"user_tz":-180,"elapsed":598,"user":{"displayName":"Никита Масловский","userId":"15665865335602303397"}},"outputId":"0ac8db29-23bf-40b2-db2b-44181c2a9669"},"execution_count":144,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0]"]},"metadata":{},"execution_count":144}]},{"cell_type":"code","source":["model.config.id2label"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gYO-k2ILkKEU","executionInfo":{"status":"ok","timestamp":1716033526196,"user_tz":-180,"elapsed":4,"user":{"displayName":"Никита Масловский","userId":"15665865335602303397"}},"outputId":"befc8b19-a0de-427d-a038-1d024925a883"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'O': 0,\n"," 'B-VIOLATION': 1,\n"," 'I-VIOLATION': 2,\n"," 'B-MISSING-BEFORE': 3,\n"," 'B-MISSING-AFTER': 4}"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":[],"metadata":{"id":"HgUXkZOPkZFM"},"execution_count":null,"outputs":[]}]}